{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b0b11bc6",
      "metadata": {},
      "source": [
        "# Python, NumPy, and Pandas\n",
        "\n",
        "This notebook is designed for students who may be brand‑new to Python. We go **slowly** and explain **why** things work, not just **how**.\n",
        "\n",
        "**How to use this notebook**\n",
        "- Read the notes in each section.\n",
        "- Run the examples.\n",
        "- Complete the **TODO** blocks. They’re short practices to build your muscle memory.\n",
        "- If you get stuck, read the example right above the TODO again.\n",
        "\n",
        "> Tip: You can run a cell with **Shift + Enter** in Jupyter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2799b90a",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "1. Python Basics: Variables, Types, Printing, Input, Comments\n",
        "2. Numbers, Strings, Booleans, `None`\n",
        "3. Collections: Lists, Tuples, Sets, Dicts\n",
        "4. Control Flow: `if`, `for`, `while`, `break`, `continue`, ternary\n",
        "5. Functions: `def`, parameters, return values, docstrings, type hints\n",
        "6. Modules & Imports: `import`, `from ... import ...`, `as`\n",
        "7. Errors & Exceptions: try/except, raising errors, assertions\n",
        "8. NumPy Essentials: arrays, dtypes, shapes, indexing, slicing, broadcasting, masking\n",
        "9. Random, Aggregations & Stats: `np.random`, `np.mean`, `np.std`, etc.\n",
        "10. Pandas Essentials: Series & DataFrame, reading CSV, inspecting, selecting, filtering\n",
        "11. Handling Missing Data, Dtypes, Dates, String Ops\n",
        "**12. Advanced Data Cleaning & Standardization** *(NEW)*\n",
        "**13. Text Processing & Regular Expressions** *(NEW)*\n",
        "**14. Data Auditing & Quality Checks** *(NEW)*\n",
        "**15. Categorical Encoding for Machine Learning** *(NEW)*\n",
        "16. GroupBy, Aggregation, Sorting, `value_counts`\n",
        "17. Merging/Joining DataFrames\n",
        "18. Exporting, Reproducibility & Project Tips\n",
        "\n",
        "**NEW SECTIONS** specifically cover all the skills needed for your loan risk prediction project!\n",
        "\n",
        "Each section ends with **TODO** practice."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f02071df",
      "metadata": {},
      "source": [
        "## 1) Python Basics\n",
        "\n",
        "**Concepts**  \n",
        "- **Variables** store values: `x = 5`  \n",
        "- **Names**: letters, digits, underscores; **cannot** start with a digit. Case‑sensitive (`score` vs `Score`).  \n",
        "- **Comments**: start with `#` and are ignored by Python.  \n",
        "- **Printing**: `print(...)` displays values.  \n",
        "- **Input** (optional here): `input()` reads user text (we rarely use it in data science notebooks).\n",
        "\n",
        "**Pro tip:** In notebooks, the **last expression** in a cell will display automatically. Use `print()` when you want explicit output anywhere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9aa3a4f7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: 5 y: 2.5 name: Ray is_ok: True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7.5"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Examples\n",
        "x = 5        # integer\n",
        "y = 2.5      # float\n",
        "name = \"Ray\" # string\n",
        "is_ok = True # boolean\n",
        "\n",
        "print(\"x:\", x, \"y:\", y, \"name:\", name, \"is_ok:\", is_ok)\n",
        "\n",
        "# The last line in a cell is echoed if it's an expression:\n",
        "x + y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb2c62d8",
      "metadata": {},
      "source": [
        "### ✅ TODO 1 — Variables & Printing\n",
        "1. Create variables: `a` (int), `b` (float), `msg` (string), `flag` (bool).\n",
        "2. Print them in a single line like: `a=..., b=..., msg=..., flag=...`.\n",
        "3. Try changing values and running again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "814f8776",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a = 10 b = 20 msg = hi flag = False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None,)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO 1 — Your code here\n",
        "a = 10\n",
        "b = 20\n",
        "msg = \"hi\"\n",
        "flag = False\n",
        "\n",
        "print(\"a =\", a, \"b =\", b, \"msg =\", msg, \"flag =\", flag), "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a52ae955",
      "metadata": {},
      "source": [
        "## 2) Numbers, Strings, Booleans, and `None`\n",
        "\n",
        "- **int**: whole numbers, e.g., `42`\n",
        "- **float**: decimals, e.g., `3.14`\n",
        "- **bool**: `True` or `False`\n",
        "- **None**: \"empty\" or \"no value yet\" placeholder\n",
        "\n",
        "**Common string operations**  \n",
        "- Concatenate: `\"Hello \" + \"World\"`  \n",
        "- f-string (preferred): `f\"Hello {name}\"`  \n",
        "- Length: `len(\"abc\")`  \n",
        "- Methods: `\"loan\".upper()`, `\" LOAN \".strip()`, `\"loan-risk\".replace(\"-\", \" \")`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5e75077f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We have 12 samples and PI ~ 3.14\n",
            "upper: LOAN | repl: loan risk | length: 7\n",
            "nothing is None\n"
          ]
        }
      ],
      "source": [
        "# Examples\n",
        "pi = 3.14159\n",
        "count = 12\n",
        "statement = f\"We have {count} samples and PI ~ {pi:.2f}\"\n",
        "upper = \"loan\".upper()\n",
        "repl = \"loan-risk\".replace(\"-\", \" \")\n",
        "length = len(\"default\")\n",
        "\n",
        "print(statement)\n",
        "print(\"upper:\", upper, \"| repl:\", repl, \"| length:\", length)\n",
        "\n",
        "nothing = None\n",
        "print(\"nothing is\", nothing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96639531",
      "metadata": {},
      "source": [
        "### ✅ TODO 2 — Strings & Numbers\n",
        "1. Make a string with your name and favorite number, using an **f-string**.\n",
        "2. Use `.upper()` and `.replace()` on any string you create.\n",
        "3. Create a variable `mystery = None` and print it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dd8910a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: Sadie | Favorite Number: 3\n",
            "SADIE\n",
            "Zadie\n"
          ]
        }
      ],
      "source": [
        "# TODO 2 — Your code here\n",
        "name = \"Sadie\"\n",
        "fav_num = \"3\"\n",
        "upper = \"Sadie\".upper()\n",
        "repl = \"Sadie\".replace(\"S\", \"Z\")\n",
        "statement = f\"Name: {name} | Favorite Number: {fav_num}\"\n",
        "print(statement)\n",
        "print(upper)\n",
        "print(repl)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "480c9afe",
      "metadata": {},
      "source": [
        "## 3) Collections: Lists, Tuples, Sets, Dicts\n",
        "\n",
        "- **List `[]`**: ordered, changeable collection. Great general container.  \n",
        "  - Indexing: `nums[0]`, slicing: `nums[1:3]`, append: `nums.append(10)`\n",
        "- **Tuple `()`**: ordered, **immutable** (can't change). Useful for \"fixed packets\" of data.\n",
        "- **Set `{}`**: **unique**, unordered elements; fast membership tests, set operations.\n",
        "- **Dict `{key: value}`**: mapping from keys to values. Keys usually strings.\n",
        "\n",
        "Why care? You’ll use **lists** and **dicts** constantly when massaging data **before** turning it into tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "10ec5f7a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "list nums: [3, 1, 4, 1] | slice nums[1:3]: [1, 4]\n",
            "tuple point: (10, 20)\n",
            "set unique: {1, 2, 3} | 2 in unique? True\n",
            "dict row: {'Loan ID': 123, 'Amount': 5000, 'Status': 'Current'} | keys: ['Loan ID', 'Amount', 'Status']\n"
          ]
        }
      ],
      "source": [
        "# Examples\n",
        "nums = [3, 1, 4]\n",
        "nums.append(1)\n",
        "print(\"list nums:\", nums, \"| slice nums[1:3]:\", nums[1:3])\n",
        "\n",
        "point = (10, 20)  # tuple\n",
        "print(\"tuple point:\", point)\n",
        "\n",
        "unique = {1, 1, 2, 3}\n",
        "print(\"set unique:\", unique, \"| 2 in unique?\", 2 in unique)\n",
        "\n",
        "row = {\"Loan ID\": 123, \"Amount\": 5000, \"Status\": \"Current\"}\n",
        "print(\"dict row:\", row, \"| keys:\", list(row.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93dc381c",
      "metadata": {},
      "source": [
        "### ✅ TODO 3 — Practice Collections\n",
        "1. Make a list of three loan amounts. Append one more amount.\n",
        "2. Create a set from that list (notice duplicates vanish).\n",
        "3. Create a dict with keys: `\"Customer ID\"`, `\"Term\"`, `\"Home Ownership\"` and fill in any values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "165752ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10, 20, 30, 40]\n",
            "{10, 20, 30}\n",
            "{'Customer ID': 123, 'Term': 2, 'Home Ownership': True}\n"
          ]
        }
      ],
      "source": [
        "# TODO 3 — Your code here\n",
        "\n",
        "loans = [10, 20, 30]\n",
        "loans.append(40)\n",
        "print(loans)\n",
        "\n",
        "loanSet = {10, 20, 30, 20}\n",
        "print(loanSet)\n",
        "\n",
        "data = {\"Customer ID\": 123, \"Term\" : 2, \"Home Ownership\": True}\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e748b448",
      "metadata": {},
      "source": [
        "## 4) Control Flow: `if`, `for`, `while`, `break`, `continue`, ternary\n",
        "\n",
        "- `if/elif/else` chooses a path.\n",
        "- `for` loops across items.\n",
        "- `while` repeats while a condition is true.\n",
        "- `break` exits a loop early; `continue` skips to next iteration.\n",
        "- Ternary: `x = A if condition else B` (compact if/else for expressions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e678d700",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grade: C\n",
            "total: 6\n",
            "i after loop: 3\n",
            "risk: low\n"
          ]
        }
      ],
      "source": [
        "# Examples\n",
        "score = 72\n",
        "if score >= 90:\n",
        "    grade = \"A\"\n",
        "elif score >= 80:\n",
        "    grade = \"B\"\n",
        "elif score >= 70:\n",
        "    grade = \"C\"\n",
        "else:\n",
        "    grade = \"D\"\n",
        "print(\"grade:\", grade)\n",
        "\n",
        "# for loop\n",
        "total = 0\n",
        "for n in [1, 2, 3]:\n",
        "    total += n\n",
        "print(\"total:\", total)\n",
        "\n",
        "# while with break\n",
        "i = 0\n",
        "while True:\n",
        "    i += 1\n",
        "    if i == 3:\n",
        "        break\n",
        "print(\"i after loop:\", i)\n",
        "\n",
        "# ternary\n",
        "risk = \"high\" if score < 70 else \"low\"\n",
        "print(\"risk:\", risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b483ad86",
      "metadata": {},
      "source": [
        "### ✅ TODO 4 — Loops & Conditions\n",
        "1. Given `amounts = [500, 1200, 3000, 250]`, make a new list containing only amounts ≥ 500 using a `for` loop and `if`.\n",
        "2. Compute the sum of the filtered list.\n",
        "3. Use a ternary expression to set `flag = \"big\"` if the sum ≥ 2000 else `\"small\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c6c4733d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[500, 1200, 3000]\n",
            "big\n"
          ]
        }
      ],
      "source": [
        "# TODO 4 — Your code here\n",
        "amounts = [500, 1200, 3000, 250]\n",
        "new_list = []\n",
        "sum = 0\n",
        "for a in amounts:\n",
        "    if a >= 500:\n",
        "        new_list.append(a)\n",
        "        sum += a\n",
        "\n",
        "print(new_list)\n",
        "\n",
        "size = \"big\" if sum >= 2000 else \"small\"\n",
        "print(size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aad27b3",
      "metadata": {},
      "source": [
        "## 5) Functions\n",
        "\n",
        "Why write functions?\n",
        "- Reuse logic, reduce repetition, write tests, and make your code readable.\n",
        "\n",
        "Key pieces:\n",
        "- `def name(params):` defines a function.\n",
        "- **Docstring** `\"\"\"Describe what it does.\"\"\"` at top of function is helpful.\n",
        "- **Type hints** (optional but recommended): `def add(a: int, b: int) -> int:`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b0fab764",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.0\n"
          ]
        }
      ],
      "source": [
        "def add(a: float, b: float) -> float:\n",
        "    \"\"\"Return the sum of a and b.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "print(add(1.5, 2.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "477ce7d2",
      "metadata": {},
      "source": [
        "### ✅ TODO 5 — Write a Function\n",
        "Write a function `is_default_risk(income, debts)` that returns `True` if `debts > income * 0.4`, else `False`.  \n",
        "Add a short docstring and type hints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a73b4af7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# TODO 5 — Your code here\n",
        "def is_default_risk(income: float, debts: float) -> bool:\n",
        "    \"\"\"Returns True if debts > income * 0.4\"\"\"\n",
        "    return debts > income * 0.4\n",
        "\n",
        "print(is_default_risk(100000, 50000))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e72c10a",
      "metadata": {},
      "source": [
        "## 6) Modules & Imports\n",
        "\n",
        "- `import math`\n",
        "- `from math import sqrt`\n",
        "- `import numpy as np` (gives a **short alias** so you type less)\n",
        "\n",
        "> In our project, we’ll often use: `import numpy as np` and `import pandas as pd`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3c5ac114",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pi: 3.141592653589793 | sqrt(9): 3.0\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from math import sqrt\n",
        "print(\"pi:\", math.pi, \"| sqrt(9):\", sqrt(9))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce486401",
      "metadata": {},
      "source": [
        "### ✅ TODO 6 — Try Imports\n",
        "1. Import the `statistics` module.\n",
        "2. Use `statistics.mean([1,2,3,4])`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "823fdfb3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5\n"
          ]
        }
      ],
      "source": [
        "# TODO 6 — Your code here\n",
        "import statistics as stats\n",
        "print(stats.mean([1,2,3,4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f376cdd4",
      "metadata": {},
      "source": [
        "## 7) Errors & Exceptions\n",
        "\n",
        "- Errors stop execution. Use `try/except` to handle.\n",
        "- `raise ValueError(\"message\")` to signal problems in your own code.\n",
        "- `assert condition, \"message\"` to catch unexpected states during development."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4b73fc7c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/2 = 5.0\n",
            "10/0 = inf\n"
          ]
        }
      ],
      "source": [
        "def safe_divide(a, b):\n",
        "    try:\n",
        "        return a / b\n",
        "    except ZeroDivisionError:\n",
        "        return float(\"inf\")\n",
        "\n",
        "print(\"10/2 =\", safe_divide(10,2))\n",
        "print(\"10/0 =\", safe_divide(10,0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c022a1f",
      "metadata": {},
      "source": [
        "### ✅ TODO 7 — Your Turn\n",
        "Write `sqrt_nonneg(x)` that returns `math.sqrt(x)` but **raises** a `ValueError` if `x < 0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "faad8363",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.0\n",
            "inf\n"
          ]
        }
      ],
      "source": [
        "# TODO 7 — Your code here\n",
        "def sqrt_nonneg(x):\n",
        "    try:\n",
        "        return math.sqrt(x)\n",
        "    except ValueError:\n",
        "        return float(\"inf\")\n",
        "    \n",
        "print(sqrt_nonneg(16))\n",
        "print(sqrt_nonneg(-4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a857ef4e",
      "metadata": {},
      "source": [
        "## 8) NumPy Essentials\n",
        "\n",
        "**What/Why:** NumPy provides fast, memory‑efficient **arrays** and mathematical operations.  \n",
        "We use NumPy for:\n",
        "- numeric arrays and vectorized math\n",
        "- broadcasting (do math across arrays of different shapes)\n",
        "- masking & boolean indexing (filtering)\n",
        "\n",
        "**Core ideas**\n",
        "- Create arrays: `np.array([...])`, `np.arange`, `np.linspace`\n",
        "- Shape: `arr.shape`, data type: `arr.dtype`\n",
        "- Indexing/slicing: `arr[0]`, `arr[1:3]`, multi‑dim: `arr[rows, cols]`\n",
        "- Broadcasting: add arrays of compatible shapes automatically\n",
        "- Masking: boolean arrays to filter values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8a69ad9b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arr: [1 2 3] | shape: (3,) | dtype: int64\n",
            "big: [0 1 2 3 4 5 6 7 8 9]\n",
            "slice big[2:7]: [2 3 4 5 6]\n",
            "a + b: [11 12 13]\n",
            "mask: [False  True  True] | a[mask]: [2 3]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([1, 2, 3], dtype=np.int64)\n",
        "print(\"arr:\", arr, \"| shape:\", arr.shape, \"| dtype:\", arr.dtype)\n",
        "\n",
        "big = np.arange(0, 10)  # 0..9\n",
        "print(\"big:\", big)\n",
        "print(\"slice big[2:7]:\", big[2:7])\n",
        "\n",
        "# Broadcasting\n",
        "a = np.array([1, 2, 3])\n",
        "b = 10\n",
        "print(\"a + b:\", a + b)\n",
        "\n",
        "# Masking\n",
        "mask = a > 1\n",
        "print(\"mask:\", mask, \"| a[mask]:\", a[mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c77a739d",
      "metadata": {},
      "source": [
        "### ✅ TODO 8 — Arrays, Shapes, Masks\n",
        "1. Create an array `vals = np.array([100, 250, 400, 50])`.\n",
        "2. Create a mask for values ≥ 200 and print the filtered result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "42785bc0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False  True  True False]\n"
          ]
        }
      ],
      "source": [
        "# TODO 8 — Your code here\n",
        "vals = np.array([100, 250, 400, 50])\n",
        "mask = vals >= 200\n",
        "print(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6aa4994",
      "metadata": {},
      "source": [
        "## 9) Random, Aggregations & Simple Stats\n",
        "\n",
        "- Random: `np.random.default_rng(seed)` then use methods like `.normal`, `.integers`\n",
        "- Aggregations: `np.sum`, `np.mean`, `np.median`, `np.std`, `np.min`, `np.max`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0eafc1af",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "samples: [ 0.30471708 -1.03998411  0.7504512   0.94056472 -1.95103519]\n",
            "mean: -0.1990572605884459 | std: 1.1163044177405164 | min: -1.9510351886538364 | max: 0.9405647163912139\n"
          ]
        }
      ],
      "source": [
        "rng = np.random.default_rng(42)\n",
        "samples = rng.normal(loc=0, scale=1, size=5)\n",
        "print(\"samples:\", samples)\n",
        "print(\"mean:\", np.mean(samples), \"| std:\", np.std(samples), \"| min:\", np.min(samples), \"| max:\", np.max(samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a57a090",
      "metadata": {},
      "source": [
        "### ✅ TODO 9 — Practice Random + Stats\n",
        "1. Create 100 random integers between 300 and 850 (inclusive of 300, exclusive of 851).  \n",
        "2. Compute mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "09d7a845",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "589.8\n",
            "149.52257354660534\n"
          ]
        }
      ],
      "source": [
        "# TODO 9 — Your code here\n",
        "rng = np.random.default_rng(42)\n",
        "nums = rng.integers(300, 851, size=100)\n",
        "print(np.mean(nums))\n",
        "print(np.std(nums))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6256bdd4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6c7e6a6b",
      "metadata": {},
      "source": [
        "## 10) Pandas Essentials\n",
        "\n",
        "Pandas gives you **Series** (1D) and **DataFrames** (2D tables).  \n",
        "We use Pandas to load CSVs, clean data, select/filter rows, create new columns, summarize, and export.\n",
        "\n",
        "**Core operations you'll use a lot:**\n",
        "- Read: `pd.read_csv(\"file.csv\")`\n",
        "- Inspect: `.head()`, `.tail()`, `.shape`, `.info()`, `.describe()`\n",
        "- Select columns: `df[[\"A\",\"B\"]]` or `df[\"A\"]`\n",
        "- Filter rows: `df[df[\"col\"] > 0]`\n",
        "- Create columns: `df[\"new\"] = df[\"old\"] * 2`\n",
        "- Rename: `df.rename(columns={\"Old\":\"New\"}, inplace=True)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "05eac2b5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan ID</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "      <td>Current</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1200</td>\n",
              "      <td>Fully Paid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3000</td>\n",
              "      <td>Defaulted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>250</td>\n",
              "      <td>Current</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Loan ID  Amount      Status\n",
              "0        1     500     Current\n",
              "1        2    1200  Fully Paid\n",
              "2        3    3000   Defaulted\n",
              "3        4     250     Current"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (4, 3)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Loan ID  4 non-null      int64 \n",
            " 1   Amount   4 non-null      int64 \n",
            " 2   Status   4 non-null      object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 228.0+ bytes\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan ID</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.500000</td>\n",
              "      <td>1237.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.290994</td>\n",
              "      <td>1241.89036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>250.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.750000</td>\n",
              "      <td>437.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.500000</td>\n",
              "      <td>850.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.250000</td>\n",
              "      <td>1650.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>3000.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Loan ID      Amount\n",
              "count  4.000000     4.00000\n",
              "mean   2.500000  1237.50000\n",
              "std    1.290994  1241.89036\n",
              "min    1.000000   250.00000\n",
              "25%    1.750000   437.50000\n",
              "50%    2.500000   850.00000\n",
              "75%    3.250000  1650.00000\n",
              "max    4.000000  3000.00000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Tiny demo DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"Loan ID\":[1,2,3,4],\n",
        "    \"Amount\":[500, 1200, 3000, 250],\n",
        "    \"Status\":[\"Current\", \"Fully Paid\", \"Defaulted\", \"Current\"]\n",
        "})\n",
        "display(df.head())\n",
        "print(\"shape:\", df.shape)\n",
        "df.info()\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbffd0bd",
      "metadata": {},
      "source": [
        "### ✅ TODO 10 — Load & Inspect\n",
        "1. Create a DataFrame with columns: `Customer ID`, `Income`, `Debt`, `Home Ownership` (4–5 rows).\n",
        "2. Show `.head()`, `.shape`, `.info()`, `.describe()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65296c6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer ID</th>\n",
              "      <th>Income</th>\n",
              "      <th>Debt</th>\n",
              "      <th>Home Ownership</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>332</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>333</td>\n",
              "      <td>20000</td>\n",
              "      <td>2000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>123</td>\n",
              "      <td>30000</td>\n",
              "      <td>3000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>321</td>\n",
              "      <td>40000</td>\n",
              "      <td>4000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Customer ID  Income  Debt  Home Ownership\n",
              "0          332   10000  1000           False\n",
              "1          333   20000  2000           False\n",
              "2          123   30000  3000            True\n",
              "3          321   40000  4000            True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 4)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype\n",
            "---  ------          --------------  -----\n",
            " 0   Customer ID     4 non-null      int64\n",
            " 1   Income          4 non-null      int64\n",
            " 2   Debt            4 non-null      int64\n",
            " 3   Home Ownership  4 non-null      bool \n",
            "dtypes: bool(1), int64(3)\n",
            "memory usage: 232.0 bytes\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer ID</th>\n",
              "      <th>Income</th>\n",
              "      <th>Debt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>277.250000</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>2500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>102.976939</td>\n",
              "      <td>12909.944487</td>\n",
              "      <td>1290.994449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>123.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>271.500000</td>\n",
              "      <td>17500.000000</td>\n",
              "      <td>1750.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>326.500000</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>2500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>332.250000</td>\n",
              "      <td>32500.000000</td>\n",
              "      <td>3250.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>333.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Customer ID        Income         Debt\n",
              "count     4.000000      4.000000     4.000000\n",
              "mean    277.250000  25000.000000  2500.000000\n",
              "std     102.976939  12909.944487  1290.994449\n",
              "min     123.000000  10000.000000  1000.000000\n",
              "25%     271.500000  17500.000000  1750.000000\n",
              "50%     326.500000  25000.000000  2500.000000\n",
              "75%     332.250000  32500.000000  3250.000000\n",
              "max     333.000000  40000.000000  4000.000000"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO 10 — Your code here\n",
        "df = pd.DataFrame({\n",
        "    \"Customer ID\": [332, 333, 123, 321],\n",
        "    \"Income\": [10000, 20000, 30000, 40000],\n",
        "    \"Debt\": [1000, 2000, 3000, 4000],\n",
        "    \"Home Ownership\": [False, False, True, True]\n",
        "})\n",
        "display(df.head())\n",
        "print(df.shape)\n",
        "df.info()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c2130c9",
      "metadata": {},
      "source": [
        "## 11) Handling Missing Data, Dtypes, Dates, and String Ops\n",
        "\n",
        "- Missing values use `np.nan` (for numbers) or `pd.NA`.\n",
        "- Detect missing: `df.isna()`, `df[\"col\"].isna()`\n",
        "- Drop missing: `df.dropna(subset=[\"col1\",\"col2\"])`\n",
        "- Fill missing: `df[\"col\"].fillna(value)`\n",
        "- Dtypes: `df.dtypes`, `df[\"col\"] = df[\"col\"].astype(\"int64\")`\n",
        "- Dates: `pd.to_datetime(df[\"when\"])`, then `.dt.year`, `.dt.month`, etc.\n",
        "- Strings: `df[\"col\"].str.upper()`, `.str.strip()`, `.str.contains(\"abc\")`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4ed6fcd5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Amount</th>\n",
              "      <th>Purpose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>debt_consolidation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500.0</td>\n",
              "      <td>credit card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Amount             Purpose\n",
              "0  1000.0  debt_consolidation\n",
              "1     NaN                home\n",
              "2   500.0         credit card\n",
              "3  2000.0                 car"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Amount</th>\n",
              "      <th>Purpose</th>\n",
              "      <th>Amount_filled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>1000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>home</td>\n",
              "      <td>1000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500.0</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>car</td>\n",
              "      <td>2000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Amount             Purpose  Amount_filled\n",
              "0  1000.0  debt_consolidation         1000.0\n",
              "1     NaN                home         1000.0\n",
              "2   500.0         credit_card          500.0\n",
              "3  2000.0                 car         2000.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amount           float64\n",
            "Purpose           object\n",
            "Amount_filled    float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "df2 = pd.DataFrame({\n",
        "    \"Amount\":[1000, None, 500, 2000],\n",
        "    \"Purpose\":[\"debt_consolidation\", \"home\", \"credit card\", \"car\"]\n",
        "})\n",
        "display(df2)\n",
        "\n",
        "# Clean strings\n",
        "df2[\"Purpose\"] = df2[\"Purpose\"].str.strip().str.replace(\" \", \"_\")\n",
        "# Handle missing\n",
        "df2[\"Amount_filled\"] = df2[\"Amount\"].fillna(df2[\"Amount\"].median())\n",
        "\n",
        "display(df2)\n",
        "print(df2.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd0eb10b",
      "metadata": {},
      "source": [
        "### ✅ TODO 11 — Clean Columns\n",
        "1. Create a DataFrame with a few missing numbers and messy strings (extra spaces/mixed case).\n",
        "2. Use `.fillna()` with median for the numeric column and `.str.strip().str.lower()` for strings.\n",
        "3. Convert a date column to datetime and print the `.dt.year`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "47bcaeb3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Income</th>\n",
              "      <th>Purpose</th>\n",
              "      <th>Income_Filled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>10000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20000.0</td>\n",
              "      <td>home</td>\n",
              "      <td>20000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>20000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40000.0</td>\n",
              "      <td>car</td>\n",
              "      <td>40000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Income             Purpose  Income_Filled\n",
              "0  10000.0  debt_consolidation        10000.0\n",
              "1  20000.0                home        20000.0\n",
              "2      NaN         credit_card        20000.0\n",
              "3  40000.0                 car        40000.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO 11 — Your code here\n",
        "df3 = pd.DataFrame({\n",
        "    \"Income\": [10000, 20000, None, 40000],\n",
        "    \"Purpose\":[\"debt_consolidation\", \"home\", \"credit card\", \"car\"]\n",
        "})\n",
        "df3[\"Income_Filled\"] = df3[\"Income\"].fillna(df3[\"Income\"].median())\n",
        "df3[\"Purpose\"] = df2[\"Purpose\"].str.strip().str.replace(\" \", \"_\")\n",
        "display(df3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "data_cleaning_intro",
      "metadata": {},
      "source": [
        "## 12) Advanced Data Cleaning & Standardization\n",
        "\n",
        "**Real-world data is messy!** Before we can analyze it, we need to clean and standardize it.\n",
        "\n",
        "**Key concepts covered:**\n",
        "- Standardizing different types of missing values\n",
        "- Using `.replace()` with dictionaries for categorical standardization\n",
        "- Recording which columns had missing values (for feature engineering)\n",
        "- Using `.mode()` for categorical imputation\n",
        "- Checking and recoding target labels\n",
        "- Grouping rare categories\n",
        "\n",
        "> **Why this matters:** Clean, consistent data is essential for machine learning models to work properly!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "standardizing_nulls",
      "metadata": {},
      "source": [
        "### 12a) Standardizing Missing Values\n",
        "\n",
        "Different systems write missing values in different ways: `'nan'`, `'NaN'`, `'NULL'`, empty strings `''`, or just spaces `' '`. \n",
        "\n",
        "**We want pandas to recognize ALL of these as missing values (`np.nan`).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "standardizing_nulls_example",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before standardizing:\n",
            "  Income   Status Score\n",
            "0  50000  Current   700\n",
            "1    nan            NaN\n",
            "2  75000     Paid   650\n",
            "3   NULL            800\n",
            "\n",
            "Missing value count before: 0\n",
            "\n",
            "After standardizing:\n",
            "    Income   Status  Score\n",
            "0  50000.0  Current  700.0\n",
            "1      NaN      NaN    NaN\n",
            "2  75000.0     Paid  650.0\n",
            "3      NaN      NaN  800.0\n",
            "\n",
            "Missing value count after: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/72/wyhp9lq90555g15fm2t545rh0000gn/T/ipykernel_7464/2071274496.py:17: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_messy.replace(['nan', 'NaN', 'NULL', '', ' '], np.nan, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Example messy data with different types of missing values\n",
        "messy_data = {\n",
        "    'Income': [50000, 'nan', 75000, 'NULL'],\n",
        "    'Status': ['Current', '', 'Paid', ' '],\n",
        "    'Score': [700, 'NaN', 650, 800]\n",
        "}\n",
        "df_messy = pd.DataFrame(messy_data)\n",
        "print(\"Before standardizing:\")\n",
        "print(df_messy)\n",
        "print(\"\\nMissing value count before:\", df_messy.isnull().sum().sum())\n",
        "\n",
        "# Standardize all types of missing values to np.nan\n",
        "# inplace=True means the DataFrame is changed directly\n",
        "df_messy.replace(['nan', 'NaN', 'NULL', '', ' '], np.nan, inplace=True)\n",
        "\n",
        "print(\"\\nAfter standardizing:\")\n",
        "print(df_messy)\n",
        "print(\"\\nMissing value count after:\", df_messy.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "standardizing_nulls_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `.replace()` finds all the values in the list and replaces them with `np.nan`\n",
        "- `np.nan` is the standard way pandas represents missing values\n",
        "- Now we can use pandas functions like `.isnull()`, `.dropna()`, and `.fillna()` properly\n",
        "- `inplace=True` means the changes are made directly to the DataFrame (no need to assign it back)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "todo_standardizing_nulls",
      "metadata": {},
      "source": [
        "### ✅ TODO 12a — Practice Standardizing Missing Values\n",
        "1. Create a DataFrame with some messy missing values (use 'N/A', 'missing', empty string)\n",
        "2. Use `.replace()` to standardize them to `np.nan`\n",
        "3. Check the before/after missing counts with `.isnull().sum()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "todo_standardizing_nulls_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Nums Strings MoreNums\n",
            "0   10   hello      100\n",
            "1  N/A              200\n",
            "2   30   world  missing\n",
            "3   50             1000\n",
            "Nums        0\n",
            "Strings     0\n",
            "MoreNums    0\n",
            "dtype: int64\n",
            "   Nums Strings  MoreNums\n",
            "0  10.0   hello     100.0\n",
            "1   NaN     NaN     200.0\n",
            "2  30.0   world       NaN\n",
            "3  50.0     NaN    1000.0\n",
            "Nums        1\n",
            "Strings     2\n",
            "MoreNums    1\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/72/wyhp9lq90555g15fm2t545rh0000gn/T/ipykernel_7464/2163746970.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_mess.replace(['N/A', '', 'missing'], np.nan, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# TODO 12a — Your code here\n",
        "mess = {\n",
        "    'Nums': [10, 'N/A', 30, 50],\n",
        "    'Strings': ['hello', '', 'world', ''],\n",
        "    'MoreNums': [100, 200, 'missing', 1000]\n",
        "}\n",
        "df_mess = pd.DataFrame(mess)\n",
        "print(df_mess)\n",
        "print(df_mess.isnull().sum())\n",
        "df_mess.replace(['N/A', '', 'missing'], np.nan, inplace=True)\n",
        "print(df_mess)\n",
        "print(df_mess.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mode_imputation",
      "metadata": {},
      "source": [
        "### 12b) Using Mode for Categorical Imputation\n",
        "\n",
        "For **categorical columns** (like 'Loan Status', 'Term'), we usually fill missing values with the **mode** (most common value).\n",
        "\n",
        "**Why?** The most common category is often a reasonable guess for missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "mode_imputation_example",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before filling missing values:\n",
            "  Loan_Status       Term Home_Ownership\n",
            "0     Current  36 months           Rent\n",
            "1        Paid  60 months            Own\n",
            "2     Current  36 months           Rent\n",
            "3         NaN        NaN           Rent\n",
            "4     Current  36 months            NaN\n",
            "5         NaN  60 months            Own\n",
            "6        Paid        NaN           Rent\n",
            "\n",
            "Missing counts:\n",
            "Loan_Status       2\n",
            "Term              2\n",
            "Home_Ownership    1\n",
            "dtype: int64\n",
            "\n",
            "Mode for Loan_Status: Current\n",
            "\n",
            "Mode for Term: 36 months\n",
            "\n",
            "Mode for Home_Ownership: Rent\n",
            "\n",
            "After filling with mode:\n",
            "  Loan_Status       Term Home_Ownership\n",
            "0     Current  36 months           Rent\n",
            "1        Paid  60 months            Own\n",
            "2     Current  36 months           Rent\n",
            "3     Current  36 months           Rent\n",
            "4     Current  36 months           Rent\n",
            "5     Current  60 months            Own\n",
            "6        Paid  36 months           Rent\n",
            "\n",
            "Missing counts after:\n",
            "Loan_Status       0\n",
            "Term              0\n",
            "Home_Ownership    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/72/wyhp9lq90555g15fm2t545rh0000gn/T/ipykernel_7464/3888446319.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_loan[col].fillna(mode_value, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Example data with missing categorical values\n",
        "loan_data = {\n",
        "    'Loan_Status': ['Current', 'Paid', 'Current', np.nan, 'Current', np.nan, 'Paid'],\n",
        "    'Term': ['36 months', '60 months', '36 months', np.nan, '36 months', '60 months', np.nan],\n",
        "    'Home_Ownership': ['Rent', 'Own', 'Rent', 'Rent', np.nan, 'Own', 'Rent']\n",
        "}\n",
        "df_loan = pd.DataFrame(loan_data)\n",
        "print(\"Before filling missing values:\")\n",
        "print(df_loan)\n",
        "print(\"\\nMissing counts:\")\n",
        "print(df_loan.isnull().sum())\n",
        "\n",
        "# Fill missing categorical values with the mode (most common value)\n",
        "for col in ['Loan_Status', 'Term', 'Home_Ownership']:\n",
        "    mode_value = df_loan[col].mode()[0]  # [0] gets the first mode in case of ties\n",
        "    print(f\"\\nMode for {col}: {mode_value}\")\n",
        "    df_loan[col].fillna(mode_value, inplace=True)\n",
        "\n",
        "print(\"\\nAfter filling with mode:\")\n",
        "print(df_loan)\n",
        "print(\"\\nMissing counts after:\")\n",
        "print(df_loan.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mode_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `.mode()` finds the most common value(s) in a column\n",
        "- `.mode()[0]` gets the first mode (in case there are ties)\n",
        "- `.fillna(value, inplace=True)` replaces missing values with the specified value\n",
        "- The `for` loop applies this to multiple columns at once"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "todo_mode_imputation",
      "metadata": {},
      "source": [
        "### ✅ TODO 12b — Practice Mode Imputation\n",
        "1. Create a DataFrame with categorical columns that have some missing values\n",
        "2. Find the mode for each categorical column using `.mode()`\n",
        "3. Fill the missing values with the mode\n",
        "4. Verify no missing values remain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "todo_mode_imputation_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 12b — Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "recording_missingness",
      "metadata": {},
      "source": [
        "### 12c) Recording Missingness (Feature Engineering)\n",
        "\n",
        "Sometimes, **the fact that a value was missing** can be useful information for prediction!\n",
        "\n",
        "**Example:** If someone didn't provide their credit score, that itself might indicate higher risk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "recording_missingness_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Create missingness indicators before filling missing values\n",
        "finance_data = {\n",
        "    'Credit_Score': [720, np.nan, 650, 800, np.nan, 690],\n",
        "    'Annual_Income': [50000, 60000, np.nan, 75000, 45000, np.nan],\n",
        "    'Loan_Amount': [10000, 15000, 12000, np.nan, 8000, 20000]\n",
        "}\n",
        "df_finance = pd.DataFrame(finance_data)\n",
        "print(\"Original data:\")\n",
        "print(df_finance)\n",
        "\n",
        "# Create missingness indicator columns BEFORE filling missing values\n",
        "df_finance['Credit_Score_missing'] = df_finance['Credit_Score'].isnull()\n",
        "df_finance['Annual_Income_missing'] = df_finance['Annual_Income'].isnull()\n",
        "df_finance['Loan_Amount_missing'] = df_finance['Loan_Amount'].isnull()\n",
        "\n",
        "print(\"\\nWith missingness indicators:\")\n",
        "print(df_finance)\n",
        "\n",
        "# Now we can fill the original columns\n",
        "df_finance['Credit_Score'].fillna(df_finance['Credit_Score'].median(), inplace=True)\n",
        "df_finance['Annual_Income'].fillna(df_finance['Annual_Income'].median(), inplace=True)\n",
        "df_finance['Loan_Amount'].fillna(0, inplace=True)\n",
        "\n",
        "print(\"\\nAfter filling missing values (but keeping missingness indicators):\")\n",
        "print(df_finance)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "recording_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `.isnull()` returns `True` for missing values, `False` otherwise\n",
        "- We create new boolean columns that record which values were originally missing\n",
        "- These \"missingness indicators\" can be useful features for machine learning\n",
        "- We do this BEFORE filling missing values, so we don't lose the information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "todo_recording_missingness",
      "metadata": {},
      "source": [
        "### ✅ TODO 12c — Practice Recording Missingness\n",
        "1. Create a DataFrame with missing values in 2-3 columns\n",
        "2. Create missingness indicator columns for each column with missing data\n",
        "3. Fill the original missing values with appropriate strategies\n",
        "4. Verify that your missingness indicators correctly show where data was originally missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "todo_recording_missingness_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 12c — Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "regex_intro",
      "metadata": {},
      "source": [
        "## 13) Text Processing & Regular Expressions\n",
        "\n",
        "**Real-world data often has numbers hidden inside text.** For example, '10+ years', '2-5 years', '$1,500'.\n",
        "\n",
        "**Regular expressions (regex)** are powerful patterns that help us find and extract specific parts of text.\n",
        "\n",
        "**Key concepts:**\n",
        "- Using `re.findall()` to extract numbers from text\n",
        "- Using `pd.cut()` to bin numeric data into categories\n",
        "- Using `.replace()` with dictionaries to standardize categories"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "regex_extracting",
      "metadata": {},
      "source": [
        "### 13a) Extracting Numbers from Text\n",
        "\n",
        "Sometimes columns have numbers mixed with text. We can use **regular expressions** to pull out just the numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "regex_extracting_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Function to extract the first number from a string\n",
        "def extract_years(text):\n",
        "    \"\"\"\n",
        "    Extract the first number from a string.\n",
        "    Returns None if no number is found.\n",
        "    \"\"\"\n",
        "    text = str(text)  # Convert to string in case it's not already\n",
        "    matches = re.findall(r'\\d+', text)  # Find all groups of digits\n",
        "    if matches:\n",
        "        return int(matches[0])  # Return the first number found\n",
        "    return None  # Return None if no number found\n",
        "\n",
        "# Example data with text containing numbers\n",
        "job_data = {\n",
        "    'Years_in_job': ['10+ years', '2-5 years', '< 1 year', '5-10 years', '1 year', 'n/a']\n",
        "}\n",
        "df_jobs = pd.DataFrame(job_data)\n",
        "print(\"Original text data:\")\n",
        "print(df_jobs)\n",
        "\n",
        "# Apply the function to extract numbers\n",
        "df_jobs['Years_numeric'] = df_jobs['Years_in_job'].apply(extract_years)\n",
        "\n",
        "print(\"\\nAfter extracting numbers:\")\n",
        "print(df_jobs)\n",
        "\n",
        "# Test the function with individual examples\n",
        "print(\"\\nTesting the function:\")\n",
        "test_strings = ['10+ years', '< 1 year', 'no experience', '2.5 years']\n",
        "for test in test_strings:\n",
        "    result = extract_years(test)\n",
        "    print(f\"'{test}' -> {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "regex_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `re.findall(r'\\d+', text)` finds all sequences of digits in the text\n",
        "  - `\\d` means \"any digit\" (0-9)\n",
        "  - `+` means \"one or more\" of the previous pattern\n",
        "  - So `\\d+` means \"one or more digits in a row\"\n",
        "- `r'...'` is a \"raw string\" - it prevents Python from interpreting backslashes specially\n",
        "- `.apply()` runs our function on every value in the column\n",
        "- `int(matches[0])` converts the first match from text to a number"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "todo_regex",
      "metadata": {},
      "source": [
        "### ✅ TODO 13a — Practice Text Extraction\n",
        "1. Create a column with salary text like '$50,000', '$75K', '$100000'\n",
        "2. Write a function to extract just the numbers (hint: `re.findall(r'\\d+', text)` finds all number groups)\n",
        "3. Apply your function to create a numeric salary column\n",
        "4. Test your function on a few example strings to make sure it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "todo_regex_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 13a — Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "binning_intro",
      "metadata": {},
      "source": [
        "### 13b) Binning Numeric Data into Categories\n",
        "\n",
        "After extracting numbers, we often want to **group them into ranges (bins)**. This makes the data easier to work with and can improve model performance.\n",
        "\n",
        "**`pd.cut()`** is perfect for this!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "binning_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continue with our job years data\n",
        "print(\"Numeric years before binning:\")\n",
        "print(df_jobs['Years_numeric'].value_counts().sort_index())\n",
        "\n",
        "# Define bins and labels\n",
        "bins = [0, 2, 5, 10, float('inf')]  # 0-2, 2-5, 5-10, 10+\n",
        "labels = ['0-2', '2-5', '5-10', '10+']\n",
        "\n",
        "# Create binned categories\n",
        "# right=False means the bin includes the left edge but not the right\n",
        "# So [0, 2) means 0 ≤ value < 2\n",
        "df_jobs['Years_binned'] = pd.cut(df_jobs['Years_numeric'], \n",
        "                                bins=bins, \n",
        "                                labels=labels, \n",
        "                                right=False)\n",
        "\n",
        "print(\"\\nAfter binning:\")\n",
        "print(df_jobs)\n",
        "print(\"\\nBinned categories count:\")\n",
        "print(df_jobs['Years_binned'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "binning_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `pd.cut()` divides numeric data into bins (ranges)\n",
        "- `bins=[0, 2, 5, 10, float('inf')]` creates 4 ranges:\n",
        "  - [0, 2): 0 to just under 2\n",
        "  - [2, 5): 2 to just under 5  \n",
        "  - [5, 10): 5 to just under 10\n",
        "  - [10, ∞): 10 and above\n",
        "- `labels` gives nice names to each bin\n",
        "- `right=False` means bins include the left edge, not the right\n",
        "- Missing values (`NaN`) remain as missing in the binned result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "todo_binning",
      "metadata": {},
      "source": [
        "### ✅ TODO 13b — Practice Binning\n",
        "1. Create a column with credit scores (numbers between 300-850)\n",
        "2. Use `pd.cut()` to bin them into categories like:\n",
        "   - 'Poor' (300-579)\n",
        "   - 'Fair' (580-669) \n",
        "   - 'Good' (670-739)\n",
        "   - 'Excellent' (740-850)\n",
        "3. Print the value counts for your binned categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "todo_binning_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 13b — Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "standardizing_categories",
      "metadata": {},
      "source": [
        "### 13c) Standardizing Categories with Dictionary Mapping\n",
        "\n",
        "Real data often has the **same category written in different ways**. For example:\n",
        "- 'Home Improvements' vs 'home improvements' vs 'Home Renovation'\n",
        "- 'Debt Consolidation' vs 'debt_consolidation'\n",
        "\n",
        "We can use `.replace()` with a **dictionary** to standardize these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "standardizing_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example data with inconsistent categories\n",
        "purpose_data = {\n",
        "    'Purpose': ['Home Improvements', 'debt_consolidation', 'Buy House', 'home improvements',\n",
        "               'Business Loan', 'Buy a Car', 'debt consolidation', 'wedding', 'VACATION',\n",
        "               'Educational Expenses', 'other', 'major_purchase']\n",
        "}\n",
        "df_purpose = pd.DataFrame(purpose_data)\n",
        "print(\"Before standardizing:\")\n",
        "print(df_purpose['Purpose'].value_counts())\n",
        "\n",
        "# Create a mapping dictionary to standardize categories\n",
        "purpose_mapping = {\n",
        "    'Home Improvements': 'Home Renovation / Improvement',\n",
        "    'home improvements': 'Home Renovation / Improvement',\n",
        "    'debt_consolidation': 'Debt Consolidation',\n",
        "    'debt consolidation': 'Debt Consolidation',\n",
        "    'Buy House': 'Home Purchase / Mortgage',\n",
        "    'Business Loan': 'Business / Startup Capital',\n",
        "    'Buy a Car': 'Car / Vehicle Purchase',\n",
        "    'wedding': 'Wedding Expenses',\n",
        "    'VACATION': 'Vacation / Travel',\n",
        "    'Educational Expenses': 'Education / Tuition Fees',\n",
        "    'other': 'Other / Miscellaneous',\n",
        "    'major_purchase': 'Business / Startup Capital'\n",
        "}\n",
        "\n",
        "# Apply the mapping\n",
        "df_purpose['Purpose_standardized'] = df_purpose['Purpose'].replace(purpose_mapping)\n",
        "\n",
        "print(\"\\nAfter standardizing:\")\n",
        "print(df_purpose)\n",
        "print(\"\\nStandardized categories count:\")\n",
        "print(df_purpose['Purpose_standardized'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "standardizing_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `.replace()` with a dictionary maps old values to new values\n",
        "- Any value not in the dictionary stays unchanged\n",
        "- This helps us group similar categories together\n",
        "- Makes the data more consistent for analysis and modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "todo_standardizing",
      "metadata": {},
      "source": [
        "### ✅ TODO 13c — Practice Category Standardization\n",
        "1. Create a DataFrame with a categorical column that has inconsistent values (like different ways to write the same category)\n",
        "2. Create a mapping dictionary to standardize them\n",
        "3. Use `.replace()` to apply your mapping\n",
        "4. Compare the value counts before and after to see the improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "todo_standardizing_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 13c — Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "auditing_intro",
      "metadata": {},
      "source": [
        "## 14) Data Auditing & Quality Checks\n",
        "\n",
        "Before building models, we need to **audit our data** to make sure everything looks correct.\n",
        "\n",
        "**Key concepts:**\n",
        "- Using `.unique()` and `.value_counts()` to examine categories\n",
        "- Mapping target labels to 0/1 for binary classification\n",
        "- Grouping rare categories into 'Other'\n",
        "- Checking for outliers and invalid values\n",
        "- Using `.clip()` to handle extreme values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "auditing_categories",
      "metadata": {},
      "source": [
        "### 14a) Auditing Categories with .unique() and .value_counts()\n",
        "\n",
        "Always check what categories you actually have in your data - you might find surprises!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "auditing_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example loan data with target labels\n",
        "loan_data = {\n",
        "    'Loan_Status': ['Fully Paid', 'Charged Off', 'fully paid', 'Default', \n",
        "                   'Fully Paid', 'Current', 'charged off', 'Fully Paid'],\n",
        "    'Risk_Level': ['Low', 'High', 'Medium', 'low', 'HIGH', 'medium', 'Low', 'High']\n",
        "}\n",
        "df_audit = pd.DataFrame(loan_data)\n",
        "\n",
        "# Check all unique values in each column\n",
        "print(\"Loan_Status unique values:\")\n",
        "print(df_audit['Loan_Status'].unique())\n",
        "print(\"\\nLoan_Status value counts:\")\n",
        "print(df_audit['Loan_Status'].value_counts())\n",
        "\n",
        "print(\"\\nRisk_Level unique values:\")\n",
        "print(df_audit['Risk_Level'].unique())\n",
        "print(\"\\nRisk_Level value counts:\")\n",
        "print(df_audit['Risk_Level'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "auditing_explanation",
      "metadata": {},
      "source": [
        "**What we found:**\n",
        "- `.unique()` shows all different values (including case differences)\n",
        "- `.value_counts()` shows how many times each value appears\n",
        "- We can spot inconsistencies like 'Fully Paid' vs 'fully paid'\n",
        "- We can see if there are unexpected categories like 'Current'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "target_mapping",
      "metadata": {},
      "source": [
        "### 14b) Mapping Target Labels to 0/1\n",
        "\n",
        "For **binary classification**, we need our target variable to be 0 (good) or 1 (bad)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "target_mapping_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, let's standardize the case issues\n",
        "df_audit['Loan_Status'] = df_audit['Loan_Status'].str.title()  # Convert to Title Case\n",
        "df_audit['Loan_Status'] = df_audit['Loan_Status'].replace({\n",
        "    'Charged Off': 'Charged Off',  # Already correct\n",
        "    'Default': 'Charged Off'       # Group similar bad outcomes\n",
        "})\n",
        "\n",
        "print(\"After standardizing cases:\")\n",
        "print(df_audit['Loan_Status'].value_counts())\n",
        "\n",
        "# Map to 0 (good) and 1 (bad) for binary classification\n",
        "# 0 = loan was paid back (good outcome)\n",
        "# 1 = loan defaulted/charged off (bad outcome)\n",
        "target_mapping = {\n",
        "    'Fully Paid': 0,     # Good outcome\n",
        "    'Charged Off': 1,    # Bad outcome\n",
        "    'Current': 0         # Assume current loans are good for now\n",
        "}\n",
        "\n",
        "df_audit['Target'] = df_audit['Loan_Status'].map(target_mapping)\n",
        "\n",
        "print(\"\\nAfter mapping to 0/1:\")\n",
        "print(df_audit[['Loan_Status', 'Target']])\n",
        "print(\"\\nTarget distribution:\")\n",
        "print(df_audit['Target'].value_counts())\n",
        "\n",
        "# Check if any values weren't mapped (would be NaN)\n",
        "unmapped = df_audit['Target'].isnull().sum()\n",
        "print(f\"\\nUnmapped values: {unmapped}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "target_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `.str.title()` converts text to Title Case (fixes 'fully paid' -> 'Fully Paid')\n",
        "- `.map()` converts each value using the dictionary\n",
        "- Values not in the dictionary become `NaN` - this helps us catch unmapped categories\n",
        "- We check for unmapped values to make sure we didn't miss anything"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "todo_auditing",
      "metadata": {},
      "source": [
        "### ✅ TODO 14a-b — Practice Auditing and Target Mapping\n",
        "1. Create a DataFrame with a target column that has mixed case and multiple ways to express the same outcome\n",
        "2. Use `.unique()` and `.value_counts()` to examine the categories\n",
        "3. Standardize the categories and map them to 0 (good) and 1 (bad)\n",
        "4. Check that no values were left unmapped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "todo_auditing_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 14a-b — Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rare_categories",
      "metadata": {},
      "source": [
        "### 14c) Grouping Rare Categories\n",
        "\n",
        "Categories that appear very few times can cause problems in modeling. We can group them into 'Other'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rare_categories_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example data with some rare categories\n",
        "purpose_data = {\n",
        "    'Purpose': ['Debt Consolidation', 'Home Purchase', 'Car Purchase', 'Wedding',\n",
        "               'Debt Consolidation', 'Vacation', 'Home Purchase', 'Education', \n",
        "               'Medical', 'Debt Consolidation', 'Wedding', 'Renewable Energy',\n",
        "               'Moving', 'Home Purchase', 'Car Purchase', 'Business']\n",
        "}\n",
        "df_rare = pd.DataFrame(purpose_data)\n",
        "\n",
        "print(\"Before grouping rare categories:\")\n",
        "counts = df_rare['Purpose'].value_counts()\n",
        "print(counts)\n",
        "\n",
        "# Find categories that appear less than 2 times\n",
        "rare_threshold = 2\n",
        "rare_categories = counts[counts < rare_threshold].index\n",
        "print(f\"\\nRare categories (< {rare_threshold} occurrences):\")\n",
        "print(list(rare_categories))\n",
        "\n",
        "# Replace rare categories with 'Other'\n",
        "df_rare['Purpose_grouped'] = df_rare['Purpose'].replace(\n",
        "    dict.fromkeys(rare_categories, 'Other')\n",
        ")\n",
        "\n",
        "print(\"\\nAfter grouping rare categories:\")\n",
        "print(df_rare['Purpose_grouped'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rare_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `counts[counts < rare_threshold]` finds categories below the threshold\n",
        "- `.index` gets the names of those rare categories\n",
        "- `dict.fromkeys(rare_categories, 'Other')` creates a mapping dictionary\n",
        "- All rare categories get mapped to 'Other'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "outlier_checking",
      "metadata": {},
      "source": [
        "### 14d) Checking for Outliers and Using .clip()\n",
        "\n",
        "Extreme values can hurt model performance. We can use `.clip()` to limit values to reasonable ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "outlier_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example data with some extreme values\n",
        "finance_data = {\n",
        "    'Credit_Score': [720, 850, 300, 950, 400, -50, 0, 800, 1000, 650],\n",
        "    'Annual_Income': [50000, 75000, 200000, -10000, 0, 45000, 1000000, 60000, 55000, 70000]\n",
        "}\n",
        "df_outliers = pd.DataFrame(finance_data)\n",
        "\n",
        "print(\"Original data with outliers:\")\n",
        "print(df_outliers.describe())\n",
        "\n",
        "# Credit scores should be between 300 and 850\n",
        "df_outliers['Credit_Score_clipped'] = df_outliers['Credit_Score'].clip(lower=300, upper=850)\n",
        "\n",
        "# Annual income should be non-negative and let's cap at 500,000\n",
        "df_outliers['Annual_Income_clipped'] = df_outliers['Annual_Income'].clip(lower=0, upper=500000)\n",
        "\n",
        "print(\"\\nAfter clipping:\")\n",
        "print(df_outliers[['Credit_Score', 'Credit_Score_clipped', 'Annual_Income', 'Annual_Income_clipped']])\n",
        "\n",
        "print(\"\\nClipped data statistics:\")\n",
        "print(df_outliers[['Credit_Score_clipped', 'Annual_Income_clipped']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "outlier_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `.clip(lower=X, upper=Y)` limits values to the range [X, Y]\n",
        "- Values below X become X\n",
        "- Values above Y become Y\n",
        "- Values in the range stay unchanged\n",
        "- This prevents extreme outliers from skewing your model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "todo_outliers",
      "metadata": {},
      "source": [
        "### ✅ TODO 14c-d — Practice Rare Categories and Outliers\n",
        "1. Create a DataFrame with:\n",
        "   - A categorical column with some rare categories (appearing only once)\n",
        "   - A numeric column with some outliers (very high or negative values)\n",
        "2. Group rare categories into 'Other' using the threshold approach\n",
        "3. Use `.clip()` to limit the numeric column to a reasonable range\n",
        "4. Compare before/after statistics to see the impact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "todo_outliers_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 14c-d — Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "encoding_intro",
      "metadata": {},
      "source": [
        "## 15) Categorical Encoding for Machine Learning\n",
        "\n",
        "**Machine learning models need numbers, not text.** We need to convert categorical variables (like 'Home', 'Rent', 'Own') into numbers.\n",
        "\n",
        "**Different types of encoding:**\n",
        "- **Label Encoding**: Each category gets a number (0, 1, 2, ...)\n",
        "- **Ordinal Encoding**: For ordered categories (like '0-2 years', '2-5 years', '5+ years')\n",
        "- **One-Hot Encoding**: Each category becomes its own binary column\n",
        "\n",
        "**When to use which?**\n",
        "- **Ordinal**: When categories have a natural order (low → medium → high)\n",
        "- **One-Hot**: When categories have no natural order (red, blue, green)\n",
        "- **Label**: Simple encoding, but be careful - the model might think higher numbers are \"better\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "encoding_imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ordinal_encoding",
      "metadata": {},
      "source": [
        "### 15a) Ordinal Encoding (For Ordered Categories)\n",
        "\n",
        "Use this when your categories have a **natural order** that should be preserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ordinal_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example data with ordered categories\n",
        "job_data = {\n",
        "    'Years_in_job': ['0-2', '2-5', '5-10', '10+', '0-2', '5-10', '2-5', '10+']\n",
        "}\n",
        "df_ordinal = pd.DataFrame(job_data)\n",
        "\n",
        "print(\"Original ordered categories:\")\n",
        "print(df_ordinal['Years_in_job'].value_counts())\n",
        "\n",
        "# Create ordinal encoder with explicit category order\n",
        "# This preserves the logical order: 0-2 < 2-5 < 5-10 < 10+\n",
        "ordinal_encoder = OrdinalEncoder(categories=[['0-2', '2-5', '5-10', '10+']])\n",
        "\n",
        "# Fit and transform the data\n",
        "# Note: we need to pass a 2D array, so we use [['column_name']]\n",
        "encoded = ordinal_encoder.fit_transform(df_ordinal[['Years_in_job']])\n",
        "df_ordinal['Years_in_job_encoded'] = encoded\n",
        "\n",
        "print(\"\\nAfter ordinal encoding:\")\n",
        "print(df_ordinal)\n",
        "\n",
        "print(\"\\nMapping (category -> number):\")\n",
        "categories = ordinal_encoder.categories_[0]\n",
        "for i, category in enumerate(categories):\n",
        "    print(f\"'{category}' -> {i}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ordinal_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `OrdinalEncoder(categories=[[...]])` lets us specify the order of categories\n",
        "- Each category gets a number: '0-2' → 0, '2-5' → 1, '5-10' → 2, '10+' → 3\n",
        "- The model will understand that 3 > 2 > 1 > 0, preserving the order\n",
        "- `.fit_transform()` learns the mapping and applies it in one step"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "label_encoding",
      "metadata": {},
      "source": [
        "### 15b) Label Encoding (Simple Category → Number)\n",
        "\n",
        "Simple encoding where each category gets a unique number. Quick but be careful about order assumptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "label_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example data with unordered categories\n",
        "simple_data = {\n",
        "    'Loan_Status': ['Current', 'Paid', 'Current', 'Default', 'Paid'],\n",
        "    'Term': ['36 months', '60 months', '36 months', '36 months', '60 months'],\n",
        "    'Home_Ownership': ['Rent', 'Own', 'Mortgage', 'Rent', 'Own']\n",
        "}\n",
        "df_label = pd.DataFrame(simple_data)\n",
        "\n",
        "print(\"Original categories:\")\n",
        "print(df_label)\n",
        "\n",
        "# Apply label encoding to multiple columns\n",
        "label_encoder = LabelEncoder()\n",
        "for col in ['Loan_Status', 'Term', 'Home_Ownership']:\n",
        "    # Handle missing values by filling with 'Missing' first\n",
        "    filled_col = df_label[col].fillna('Missing')\n",
        "    df_label[f'{col}_encoded'] = label_encoder.fit_transform(filled_col)\n",
        "    \n",
        "    # Show the mapping\n",
        "    print(f\"\\n{col} mapping:\")\n",
        "    unique_values = filled_col.unique()\n",
        "    encoded_values = label_encoder.fit_transform(unique_values)\n",
        "    for orig, enc in zip(unique_values, encoded_values):\n",
        "        print(f\"  '{orig}' -> {enc}\")\n",
        "\n",
        "print(\"\\nFinal encoded data:\")\n",
        "print(df_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "label_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `LabelEncoder()` assigns a unique number to each category\n",
        "- The numbers are assigned alphabetically by default\n",
        "- We handle missing values by filling with 'Missing' before encoding\n",
        "- **Warning:** The model might interpret the numbers as having order (0 < 1 < 2), even when there isn't a natural order"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "onehot_encoding",
      "metadata": {},
      "source": [
        "### 15c) One-Hot Encoding (Each Category = New Column)\n",
        "\n",
        "Creates a new binary column for each category. Best when categories have no natural order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "onehot_example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example data for one-hot encoding\n",
        "purpose_data = {\n",
        "    'Purpose': ['Home Purchase', 'Car', 'Debt Consolidation', 'Education', \n",
        "               'Home Purchase', 'Car', np.nan, 'Debt Consolidation']\n",
        "}\n",
        "df_onehot = pd.DataFrame(purpose_data)\n",
        "\n",
        "print(\"Original categories:\")\n",
        "print(df_onehot['Purpose'].value_counts(dropna=False))\n",
        "\n",
        "# Create one-hot encoder\n",
        "# sparse_output=False gives us a regular array (not a sparse matrix)\n",
        "# drop='first' prevents the \"dummy variable trap\" (removes one category)\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
        "\n",
        "# Handle missing values and encode\n",
        "purpose_filled = df_onehot[['Purpose']].fillna('Missing')\n",
        "encoded_array = onehot_encoder.fit_transform(purpose_filled)\n",
        "\n",
        "# Create DataFrame with proper column names\n",
        "feature_names = onehot_encoder.get_feature_names_out(['Purpose'])\n",
        "encoded_df = pd.DataFrame(encoded_array, columns=feature_names, index=df_onehot.index)\n",
        "\n",
        "print(\"\\nOne-hot encoded columns:\")\n",
        "print(encoded_df)\n",
        "\n",
        "# Combine with original data (dropping the original categorical column)\n",
        "final_df = pd.concat([df_onehot.drop('Purpose', axis=1), encoded_df], axis=1)\n",
        "print(\"\\nFinal combined data:\")\n",
        "print(final_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "onehot_explanation",
      "metadata": {},
      "source": [
        "**What does this do?**\n",
        "- `OneHotEncoder` creates a binary column for each category\n",
        "- `drop='first'` removes one column to prevent multicollinearity (dummy variable trap)\n",
        "- `sparse_output=False` gives us a regular array instead of a sparse matrix\n",
        "- `handle_unknown='ignore'` won't crash if it sees new categories later\n",
        "- Each row has exactly one '1' and the rest '0's (indicating which category it belongs to)\n",
        "- We use `pd.concat()` to combine the encoded columns with the rest of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "todo_encoding",
      "metadata": {},
      "source": [
        "### ✅ TODO 15a-c — Practice All Encoding Types\n",
        "1. **Ordinal Encoding**: Create a column with ordered categories (like education levels: 'High School' < 'Bachelor' < 'Master' < 'PhD'). Encode it preserving the order.\n",
        "\n",
        "2. **Label Encoding**: Create 2-3 simple categorical columns and apply label encoding to each.\n",
        "\n",
        "3. **One-Hot Encoding**: Create a column with unordered categories (like colors or cities) and apply one-hot encoding. Join the result back to your DataFrame.\n",
        "\n",
        "4. **Compare**: Look at the different results and think about when you'd use each approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "todo_encoding_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 15a-c — Your code here\n",
        "\n",
        "# 1. Ordinal encoding practice\n",
        "\n",
        "\n",
        "# 2. Label encoding practice  \n",
        "\n",
        "\n",
        "# 3. One-hot encoding practice\n",
        "\n",
        "\n",
        "# 4. Compare and discuss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a11226cb",
      "metadata": {},
      "source": [
        "## 16) Exporting & Project Tips\n",
        "\n",
        "- Save to CSV: `df.to_csv(\"clean.csv\", index=False)`\n",
        "- Reproducibility:\n",
        "  - Keep a **requirements.txt**\n",
        "  - Use a **virtual environment** (we recommend `pyenv` + `venv` in this project)\n",
        "  - Seed randomness (e.g., `rng = np.random.default_rng(42)`)\n",
        "- Good habits:\n",
        "  - Add comments and short docstrings.\n",
        "  - Write small, testable functions.\n",
        "  - Prefer **clear** over **clever**.\n",
        "\n",
        "### ✅ TODO 16 — Save\n",
        "1. Save any DataFrame you made as `demo_output.csv` (no index).\n",
        "2. Read it back and show its `.head()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1be838f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 16 — Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be3ecdcb",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## You made it! 🎉\n",
        "\n",
        "Next up in this project: preprocessing and modeling."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
